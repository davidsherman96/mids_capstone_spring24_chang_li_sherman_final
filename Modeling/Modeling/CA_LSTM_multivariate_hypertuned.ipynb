{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oeCE85RZaBN0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder,MinMaxScaler, StandardScaler\n",
        "import csv\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4dmgFLz8_ySQ"
      },
      "outputs": [],
      "source": [
        "# Set random seed for TensorFlow\n",
        "tf.random.set_seed(123)\n",
        "\n",
        "# Set random seed for Python\n",
        "np.random.seed(123)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VHbe-92aulGr"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.set_random_seed(1)\n",
        "\n",
        "tf.config.experimental.enable_op_determinism()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfUWkEhXh31i",
        "outputId": "5ea614c4-f470-42b8-d2b2-095c1c027a4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_1Ua7mbsbUOr"
      },
      "outputs": [],
      "source": [
        "\n",
        "data_all_county = pd.read_csv('/content/drive/My Drive/time_series/CA_data_lat_log_weekly.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_all_county['date'] = pd.to_datetime(data_all_county['date'])\n",
        "data_all_county['month'] = data_all_county['date'].dt.month\n",
        "data_all_county['month'] = data_all_county['month'].astype('category')"
      ],
      "metadata": {
        "id": "OT-Omi5j_Xyl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkZqApXYXb-9"
      },
      "source": [
        "Define helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fIDCIpwSXXKt"
      },
      "outputs": [],
      "source": [
        "def ts_multi_data_prep(dataset, target, start, end, window, step_out):\n",
        "    X = []\n",
        "    y = []\n",
        "    start = start + window\n",
        "    if end is None:\n",
        "        end = len(dataset) - step_out\n",
        "        #end = len(dataset)\n",
        "    for i in range(start, end):\n",
        "        indices = range(i-window, i)\n",
        "        X.append(dataset[indices])\n",
        "\n",
        "        indicey = range(i, i+step_out) #revise the window definition\n",
        "        y.append(target[indicey])\n",
        "    return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vp6wtluEXfZb"
      },
      "outputs": [],
      "source": [
        "def timeseries_evaluation_metrics_func(y_true, y_pred):\n",
        "    def mean_absolute_percentage_error(y_true, y_pred):\n",
        "        y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "    print('Evaluation metric results:-')\n",
        "    mse = metrics.mean_squared_error(y_true.flatten(), y_pred.flatten())\n",
        "    mae = metrics.mean_absolute_error(y_true.flatten(), y_pred.flatten())\n",
        "    rmse = np.sqrt(mse)\n",
        "    #mape = mean_absolute_percentage_error(y_true.flatten(), y_pred.flatten())\n",
        "    r2 = metrics.r2_score(y_true.flatten(), y_pred.flatten())\n",
        "    #print(f'MSE is : {mse}')\n",
        "    #print(f'MAE is : {mae}')\n",
        "    #print(f'RMSE is : {rmse}')\n",
        "    #print(f'MAPE is : {mape}')\n",
        "    #print(f'R2 is : {r2}\\n')\n",
        "    return mse, mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DZJVpSJ_49m2"
      },
      "outputs": [],
      "source": [
        "def timeseries_evaluation_metrics_binary(y_true, y_pred):\n",
        "    print('Evaluation metric results:-')\n",
        "    accuracy = accuracy_score(y_true.flatten(), y_pred.flatten())\n",
        "    precision = precision_score(y_true.flatten(), y_pred.flatten(), average='macro')\n",
        "    recall = recall_score(y_true.flatten(), y_pred.flatten(), average='macro')\n",
        "    f1 = f1_score(y_true.flatten(), y_pred.flatten(), average='macro')\n",
        "\n",
        "    #print(f'Accuracy: {accuracy}')\n",
        "    #print(f'Precision: {precision}')\n",
        "    #print(f'Recall: {recall}')\n",
        "    #print(f'F1-score: {f1}\\n')\n",
        "    return f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xxvHTDdUqxyN"
      },
      "outputs": [],
      "source": [
        "def transform_county_data(x_data_array, y_data_array):\n",
        "    # Lists to store x_train_c and y_train_c arrays\n",
        "    x_c_list = []\n",
        "    y_c_list = []\n",
        "    # Divide the arrays into 'unique_fips_count' number of subarrays\n",
        "    x_subarrays = np.array_split(x_data_array, unique_fips_count, axis=0)\n",
        "    y_subarrays = np.array_split(y_data_array, unique_fips_count, axis=0)\n",
        "\n",
        "    # Combine x_subarrays and y_subarrays into tuples\n",
        "    data_tuples = [(x_subarray, y_subarray) for x_subarray, y_subarray in zip(x_subarrays, y_subarrays)]\n",
        "\n",
        "    # Print or use the data tuples as needed\n",
        "    for idx, data_tuple in enumerate(data_tuples):\n",
        "        x_window_c, y_window_c = ts_multi_data_prep(data_tuple[0],data_tuple[1], 0, None, hist_window, step_out)\n",
        "        # Append x_window_c and y_window_c arrays to lists\n",
        "        x_c_list.append(x_window_c)\n",
        "        y_c_list.append(y_window_c)\n",
        "\n",
        "    # Stack arrays in lists to create x_train_c and y_train_c\n",
        "    x_all_county = np.vstack(x_c_list)\n",
        "    y_all_county = np.vstack(y_c_list)\n",
        "\n",
        "    return x_all_county, y_all_county"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BJyFdGZFeeVi"
      },
      "outputs": [],
      "source": [
        "\n",
        "x_train_c, y_train_c, x_vali_c, y_vali_c, x_test_c, y_test_c = [], [], [], [], [], []\n",
        "unique_fips = data_all_county['fips'].unique()\n",
        "unique_fips_count = data_all_county['fips'].nunique()\n",
        "for fips in unique_fips:\n",
        "    # Extract dataframe for the current FIPS value\n",
        "    data_county = data_all_county[data_all_county['fips'] == fips]\n",
        "\n",
        "    X_data = data_county[['lat','lon','PRECTOT', 'PS', 'QV2M', 'T2M', 'T2MDEW', 'T2MWET',\n",
        "       'T2M_MAX', 'T2M_MIN', 'T2M_RANGE', 'TS', 'WS10M', 'WS10M_MAX',\n",
        "       'WS10M_MIN', 'WS10M_RANGE', 'WS50M', 'WS50M_MAX', 'WS50M_MIN',\n",
        "       'WS50M_RANGE', 'score','month']]\n",
        "    Y_data = data_county[['score']]\n",
        "    #train_val_test split 70%-10%-20%\n",
        "    n = len(X_data)\n",
        "\n",
        "    x_train_county = X_data[0:int(n*0.7)]\n",
        "    y_train_county = Y_data[0:int(n*0.7)]\n",
        "    x_vali_county = X_data[int(n*0.7):int(n*0.8)]\n",
        "    y_vali_county = Y_data[int(n*0.7):int(n*0.8)]\n",
        "    x_test_county = X_data[int(n*0.8):]\n",
        "    y_test_county = Y_data[int(n*0.8):]\n",
        "\n",
        "\n",
        "    if fips == 6001:\n",
        "        x_train_c, y_train_c, x_vali_c, y_vali_c, x_test_c, y_test_c = x_train_county, y_train_county, x_vali_county, y_vali_county, x_test_county, y_test_county\n",
        "\n",
        "    else:\n",
        "        x_train_c = np.concatenate((x_train_c, x_train_county), axis=0)\n",
        "        y_train_c = np.concatenate((y_train_c, y_train_county), axis=0)\n",
        "        x_vali_c = np.concatenate((x_vali_c, x_vali_county), axis=0)\n",
        "        y_vali_c = np.concatenate((y_vali_c, y_vali_county), axis=0)\n",
        "        x_test_c = np.concatenate((x_test_c, x_test_county), axis=0)\n",
        "        y_test_c = np.concatenate((y_test_c, y_test_county), axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MjYfAZXoYPE7"
      },
      "outputs": [],
      "source": [
        "X_scaler_train = MinMaxScaler()\n",
        "Y_scaler_train = MinMaxScaler()\n",
        "X_scaler_test = MinMaxScaler()\n",
        "Y_scaler_test = MinMaxScaler()\n",
        "X_scaler_vali = MinMaxScaler()\n",
        "Y_scaler_vali = MinMaxScaler()\n",
        "x_train_data = X_scaler_train.fit_transform(x_train_c)\n",
        "y_train_data = Y_scaler_train.fit_transform(y_train_c)\n",
        "x_vali_data = X_scaler_vali.fit_transform(x_vali_c)\n",
        "y_vali_data = Y_scaler_vali.fit_transform(y_vali_c)\n",
        "x_test_data = X_scaler_test.fit_transform(x_test_c)\n",
        "y_test_data = Y_scaler_test.fit_transform(y_test_c)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NOygAYEWhEHl"
      },
      "outputs": [],
      "source": [
        "def modeling1(hist_window, step_out, unit1, unit2, drop1, drop2, flag_report):\n",
        "\n",
        "  x_train, y_train = transform_county_data(x_train_data, y_train_data)\n",
        "  x_vali, y_vali = transform_county_data(x_vali_data, y_vali_data)\n",
        "  x_test, y_test = transform_county_data(x_test_data, y_test_data)\n",
        "  batch_size = 128\n",
        "  buffer_size = 256\n",
        "\n",
        "  train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "  train_data = train_data.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
        "\n",
        "  val_data = tf.data.Dataset.from_tensor_slices((x_vali, y_vali))\n",
        "  val_data = val_data.batch(batch_size).repeat()\n",
        "\n",
        "  lstm_model = tf.keras.models.Sequential()\n",
        "  lstm_model.add(tf.keras.layers.LSTM(unit1,input_shape=x_train.shape[-2:],return_sequences=True))\n",
        "  lstm_model.add(tf.keras.layers.Dropout(drop1)),\n",
        "  lstm_model.add(tf.keras.layers.LSTM(units=unit2,return_sequences=False)),\n",
        "  lstm_model.add(tf.keras.layers.Dropout(drop2)),\n",
        "  lstm_model.add(tf.keras.layers.Dense(units=step_out)),\n",
        "  lstm_model.compile(optimizer='adam', loss='mae')\n",
        "\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='min')\n",
        "  history = lstm_model.fit(train_data, epochs=150, steps_per_epoch=50, validation_data=val_data, validation_steps=150, verbose=0, callbacks=[early_stopping])\n",
        "  y_test_pred = lstm_model.predict(x_test)\n",
        "  y_test_pred_Inverse = Y_scaler_test.inverse_transform(y_test_pred)\n",
        "  y_test_pred_Inverse_ordinal = np.round(y_test_pred_Inverse).astype(int)\n",
        "  y_test_reshaped = np.squeeze(y_test, axis=-1)\n",
        "  y_test_Inverse = Y_scaler_test.inverse_transform(y_test_reshaped)\n",
        "  y_test_Inverse_ordinal = np.round(y_test_Inverse).astype(int)\n",
        "  mse, mae = timeseries_evaluation_metrics_func(y_test_Inverse,y_test_pred_Inverse)\n",
        "  threshold = 2.5\n",
        "  y_test_Inverse_binary = np.where(y_test_Inverse >= threshold, 1, 0)\n",
        "  y_test_pred_Inverse_binary = np.where(y_test_pred_Inverse >= threshold, 1, 0)\n",
        "  f1 = timeseries_evaluation_metrics_binary(y_test_Inverse_binary,y_test_pred_Inverse_binary)\n",
        "  if flag_report:\n",
        "    classification_metrics = classification_report(y_test_Inverse_binary.flatten(),y_test_pred_Inverse_binary.flatten())\n",
        "    print(classification_metrics)\n",
        "\n",
        "  print(f'Unit1: {unit1}, Unit2: {unit2}, Dropout1: {drop1}, Dropout2: {drop2}, F1: {f1}, MSE: {mse}, MAE: {mae}')\n",
        "  return f1, mse, mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-cWA8JVdbQw",
        "outputId": "dbaa0240-c8cd-4aa8-e3b4-b429b6578ef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27: early stopping\n",
            "323/323 [==============================] - 2s 4ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98    110778\n",
            "           1       0.94      0.66      0.78     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.95      0.83      0.88    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 150, Unit2: 100, Dropout1: 0.1, Dropout2: 0.1, F1: 0.8784395883154871, MSE: 0.3181722717057262, MAE: 0.3425203108974308\n",
            "Epoch 32: early stopping\n",
            "323/323 [==============================] - 2s 4ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.89      0.76      0.82     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.93      0.87      0.90    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 150, Unit2: 100, Dropout1: 0.1, Dropout2: 0.2, F1: 0.8996470064870349, MSE: 0.3096652224166597, MAE: 0.32584392218995745\n",
            "Epoch 45: early stopping\n",
            "323/323 [==============================] - 2s 3ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.92      0.73      0.81     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.94      0.86      0.90    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 150, Unit2: 100, Dropout1: 0.2, Dropout2: 0.1, F1: 0.895365311374105, MSE: 0.31963837695589536, MAE: 0.3211865663819384\n",
            "Epoch 28: early stopping\n",
            "323/323 [==============================] - 2s 3ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98    110778\n",
            "           1       0.94      0.69      0.80     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.95      0.84      0.89    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 150, Unit2: 100, Dropout1: 0.2, Dropout2: 0.2, F1: 0.8883835839962828, MSE: 0.3198145707745575, MAE: 0.3379809639624273\n",
            "Epoch 26: early stopping\n",
            "323/323 [==============================] - 2s 4ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.91      0.74      0.82     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.94      0.87      0.90    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 150, Unit2: 75, Dropout1: 0.1, Dropout2: 0.1, F1: 0.8983441288863587, MSE: 0.30799857256189955, MAE: 0.3263954781377991\n",
            "Epoch 26: early stopping\n",
            "323/323 [==============================] - 2s 4ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98    110778\n",
            "           1       0.86      0.80      0.83     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.92      0.89      0.90    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 150, Unit2: 75, Dropout1: 0.1, Dropout2: 0.2, F1: 0.9033698113339389, MSE: 0.3187919051768611, MAE: 0.3422593790833863\n",
            "Epoch 45: early stopping\n",
            "323/323 [==============================] - 2s 4ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.90      0.72      0.80     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.94      0.86      0.89    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 150, Unit2: 75, Dropout1: 0.2, Dropout2: 0.1, F1: 0.8902375384211163, MSE: 0.3559557596872694, MAE: 0.35114119154492063\n",
            "Epoch 28: early stopping\n",
            "323/323 [==============================] - 2s 3ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.93      0.72      0.81     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.95      0.86      0.90    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 150, Unit2: 75, Dropout1: 0.2, Dropout2: 0.2, F1: 0.896734492725269, MSE: 0.31319091575069025, MAE: 0.3264657771914569\n",
            "Epoch 59: early stopping\n",
            "323/323 [==============================] - 2s 3ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.91      0.72      0.81     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.94      0.86      0.89    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 150, Unit2: 50, Dropout1: 0.1, Dropout2: 0.1, F1: 0.8924883769890628, MSE: 0.34470681572846634, MAE: 0.33479001908002126\n",
            "Epoch 39: early stopping\n",
            "323/323 [==============================] - 2s 3ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.92      0.71      0.80     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.94      0.85      0.89    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 150, Unit2: 50, Dropout1: 0.1, Dropout2: 0.2, F1: 0.8903573384513545, MSE: 0.3411360155644087, MAE: 0.3560671218105303\n",
            "Epoch 46: early stopping\n",
            "323/323 [==============================] - 2s 3ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.88      0.77      0.82     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.93      0.88      0.90    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 150, Unit2: 50, Dropout1: 0.2, Dropout2: 0.1, F1: 0.9022893050609535, MSE: 0.31713817373277337, MAE: 0.3335716446234319\n",
            "Epoch 46: early stopping\n",
            "323/323 [==============================] - 2s 3ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.87      0.77      0.82     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.92      0.88      0.90    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 150, Unit2: 50, Dropout1: 0.2, Dropout2: 0.2, F1: 0.8977855076427985, MSE: 0.322202508299011, MAE: 0.34071973943349165\n",
            "Epoch 45: early stopping\n",
            "323/323 [==============================] - 2s 3ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.93      0.71      0.81     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.95      0.85      0.89    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 100, Unit2: 100, Dropout1: 0.1, Dropout2: 0.1, F1: 0.8938623640595684, MSE: 0.31108903014679995, MAE: 0.32643955320070106\n",
            "Epoch 53: early stopping\n",
            "323/323 [==============================] - 2s 3ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98    110778\n",
            "           1       0.93      0.69      0.79     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.95      0.84      0.89    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 100, Unit2: 100, Dropout1: 0.1, Dropout2: 0.2, F1: 0.8851903209354675, MSE: 0.33017510820922213, MAE: 0.33986496775165664\n",
            "Epoch 39: early stopping\n",
            "323/323 [==============================] - 2s 3ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.93      0.72      0.81     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.95      0.86      0.90    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 100, Unit2: 100, Dropout1: 0.2, Dropout2: 0.1, F1: 0.8953916308879302, MSE: 0.3208252172064418, MAE: 0.3362609622198416\n",
            "Epoch 45: early stopping\n",
            "323/323 [==============================] - 2s 3ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.91      0.73      0.81     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.94      0.86      0.90    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 100, Unit2: 100, Dropout1: 0.2, Dropout2: 0.2, F1: 0.8958882346737024, MSE: 0.3043885786669295, MAE: 0.326911314911826\n",
            "Epoch 38: early stopping\n",
            "323/323 [==============================] - 2s 3ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.91      0.75      0.82     13110\n",
            "\n",
            "    accuracy                           0.97    123888\n",
            "   macro avg       0.94      0.87      0.90    123888\n",
            "weighted avg       0.96      0.97      0.96    123888\n",
            "\n",
            "Unit1: 100, Unit2: 75, Dropout1: 0.1, Dropout2: 0.1, F1: 0.9005234902100712, MSE: 0.32259146169953173, MAE: 0.32762094304624395\n",
            "Epoch 45: early stopping\n",
            "323/323 [==============================] - 2s 4ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.93      0.72      0.81     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.95      0.86      0.90    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 100, Unit2: 75, Dropout1: 0.1, Dropout2: 0.2, F1: 0.8960427364096295, MSE: 0.3122588004651421, MAE: 0.3196674871694842\n",
            "Epoch 45: early stopping\n",
            "323/323 [==============================] - 2s 4ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.93      0.73      0.81     13110\n",
            "\n",
            "    accuracy                           0.97    123888\n",
            "   macro avg       0.95      0.86      0.90    123888\n",
            "weighted avg       0.96      0.97      0.96    123888\n",
            "\n",
            "Unit1: 100, Unit2: 75, Dropout1: 0.2, Dropout2: 0.1, F1: 0.8978258680627142, MSE: 0.3058021581331728, MAE: 0.3177369318049358\n",
            "Epoch 25: early stopping\n",
            "323/323 [==============================] - 2s 3ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98    110778\n",
            "           1       0.94      0.65      0.77     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.95      0.82      0.87    123888\n",
            "weighted avg       0.96      0.96      0.95    123888\n",
            "\n",
            "Unit1: 100, Unit2: 75, Dropout1: 0.2, Dropout2: 0.2, F1: 0.8713554483023498, MSE: 0.33219226563715765, MAE: 0.3556954984919707\n",
            "Epoch 59: early stopping\n",
            "323/323 [==============================] - 2s 3ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.91      0.75      0.82     13110\n",
            "\n",
            "    accuracy                           0.97    123888\n",
            "   macro avg       0.94      0.87      0.90    123888\n",
            "weighted avg       0.96      0.97      0.96    123888\n",
            "\n",
            "Unit1: 100, Unit2: 50, Dropout1: 0.1, Dropout2: 0.1, F1: 0.9009662777746954, MSE: 0.316704360881716, MAE: 0.32244294422704856\n",
            "Epoch 45: early stopping\n",
            "323/323 [==============================] - 2s 3ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.92      0.73      0.81     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.95      0.86      0.90    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 100, Unit2: 50, Dropout1: 0.1, Dropout2: 0.2, F1: 0.8972868972408667, MSE: 0.3157402157942682, MAE: 0.3282403716865106\n",
            "Epoch 46: early stopping\n",
            "323/323 [==============================] - 2s 3ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.88      0.75      0.81     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.92      0.87      0.89    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 100, Unit2: 50, Dropout1: 0.2, Dropout2: 0.1, F1: 0.8932667771745963, MSE: 0.33583856251826266, MAE: 0.340078979303363\n",
            "Epoch 59: early stopping\n",
            "323/323 [==============================] - 2s 3ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.88      0.76      0.81     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.92      0.87      0.90    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 100, Unit2: 50, Dropout1: 0.2, Dropout2: 0.2, F1: 0.8960779071318675, MSE: 0.3276322340625595, MAE: 0.34300391983172573\n",
            "Epoch 14: early stopping\n",
            "323/323 [==============================] - 2s 4ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98    110778\n",
            "           1       0.95      0.64      0.77     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.95      0.82      0.87    123888\n",
            "weighted avg       0.96      0.96      0.95    123888\n",
            "\n",
            "Unit1: 75, Unit2: 100, Dropout1: 0.1, Dropout2: 0.1, F1: 0.8717022552644889, MSE: 0.3261946484875869, MAE: 0.3524700006931349\n",
            "Epoch 46: early stopping\n",
            "323/323 [==============================] - 2s 5ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.90      0.75      0.82     13110\n",
            "\n",
            "    accuracy                           0.97    123888\n",
            "   macro avg       0.94      0.87      0.90    123888\n",
            "weighted avg       0.96      0.97      0.96    123888\n",
            "\n",
            "Unit1: 75, Unit2: 100, Dropout1: 0.1, Dropout2: 0.2, F1: 0.9010283733479367, MSE: 0.3121234837013145, MAE: 0.3201110397717642\n",
            "Epoch 45: early stopping\n",
            "323/323 [==============================] - 2s 4ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.90      0.75      0.81     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.93      0.87      0.90    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 75, Unit2: 100, Dropout1: 0.2, Dropout2: 0.1, F1: 0.8970561828388688, MSE: 0.30884661973118815, MAE: 0.3313381783535894\n",
            "Epoch 26: early stopping\n",
            "323/323 [==============================] - 2s 3ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98    110778\n",
            "           1       0.84      0.81      0.82     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.91      0.89      0.90    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 75, Unit2: 100, Dropout1: 0.2, Dropout2: 0.2, F1: 0.9008720538425167, MSE: 0.3317398118148993, MAE: 0.35709048551041195\n",
            "Epoch 59: early stopping\n",
            "323/323 [==============================] - 2s 3ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.90      0.75      0.82     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.94      0.87      0.90    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 75, Unit2: 75, Dropout1: 0.1, Dropout2: 0.1, F1: 0.8982004645621711, MSE: 0.3240712695573922, MAE: 0.32824338919757284\n",
            "Epoch 59: early stopping\n",
            "323/323 [==============================] - 2s 3ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.87      0.76      0.81     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.92      0.88      0.90    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 75, Unit2: 75, Dropout1: 0.1, Dropout2: 0.2, F1: 0.8962318177553285, MSE: 0.3265809060314951, MAE: 0.33314404434522543\n",
            "Epoch 39: early stopping\n",
            "323/323 [==============================] - 2s 3ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.92      0.72      0.80     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.94      0.85      0.89    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 75, Unit2: 75, Dropout1: 0.2, Dropout2: 0.1, F1: 0.8916763614508293, MSE: 0.3643254381322285, MAE: 0.35971856207908465\n",
            "Epoch 59: early stopping\n",
            "323/323 [==============================] - 2s 3ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.90      0.75      0.82     13110\n",
            "\n",
            "    accuracy                           0.97    123888\n",
            "   macro avg       0.94      0.87      0.90    123888\n",
            "weighted avg       0.96      0.97      0.96    123888\n",
            "\n",
            "Unit1: 75, Unit2: 75, Dropout1: 0.2, Dropout2: 0.2, F1: 0.9005584145924985, MSE: 0.3191804988666529, MAE: 0.3289371976571081\n",
            "Epoch 52: early stopping\n",
            "323/323 [==============================] - 2s 3ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.93      0.73      0.81     13110\n",
            "\n",
            "    accuracy                           0.97    123888\n",
            "   macro avg       0.95      0.86      0.90    123888\n",
            "weighted avg       0.96      0.97      0.96    123888\n",
            "\n",
            "Unit1: 75, Unit2: 50, Dropout1: 0.1, Dropout2: 0.1, F1: 0.8975706777223793, MSE: 0.34967349668821013, MAE: 0.35095302903513953\n",
            "Epoch 59: early stopping\n",
            "323/323 [==============================] - 2s 4ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.90      0.74      0.81     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.94      0.86      0.90    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 75, Unit2: 50, Dropout1: 0.1, Dropout2: 0.2, F1: 0.8956160591806177, MSE: 0.3219407680688878, MAE: 0.3316226343498728\n",
            "Epoch 19: early stopping\n",
            "323/323 [==============================] - 2s 3ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97    110778\n",
            "           1       0.94      0.59      0.73     13110\n",
            "\n",
            "    accuracy                           0.95    123888\n",
            "   macro avg       0.95      0.79      0.85    123888\n",
            "weighted avg       0.95      0.95      0.95    123888\n",
            "\n",
            "Unit1: 75, Unit2: 50, Dropout1: 0.2, Dropout2: 0.1, F1: 0.8509442049529969, MSE: 0.3255061836263033, MAE: 0.3630221070386559\n",
            "Epoch 33: early stopping\n",
            "323/323 [==============================] - 2s 3ms/step\n",
            "Evaluation metric results:-\n",
            "Evaluation metric results:-\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98    110778\n",
            "           1       0.92      0.70      0.79     13110\n",
            "\n",
            "    accuracy                           0.96    123888\n",
            "   macro avg       0.94      0.84      0.89    123888\n",
            "weighted avg       0.96      0.96      0.96    123888\n",
            "\n",
            "Unit1: 75, Unit2: 50, Dropout1: 0.2, Dropout2: 0.2, F1: 0.8850115835836764, MSE: 0.33830323420745734, MAE: 0.3632818185401223\n",
            "# Hist_Window   Step_Out   Unit1   Unit2   Dropout1   Dropout2   F1    MSE       MAE\n",
            "30            12         150     100     0.1        0.1        0.8784     0.3182     0.3425    \n",
            "30            12         150     100     0.1        0.2        0.8996     0.3097     0.3258    \n",
            "30            12         150     100     0.2        0.1        0.8954     0.3196     0.3212    \n",
            "30            12         150     100     0.2        0.2        0.8884     0.3198     0.3380    \n",
            "30            12         150     75      0.1        0.1        0.8983     0.3080     0.3264    \n",
            "30            12         150     75      0.1        0.2        0.9034     0.3188     0.3423    \n",
            "30            12         150     75      0.2        0.1        0.8902     0.3560     0.3511    \n",
            "30            12         150     75      0.2        0.2        0.8967     0.3132     0.3265    \n",
            "30            12         150     50      0.1        0.1        0.8925     0.3447     0.3348    \n",
            "30            12         150     50      0.1        0.2        0.8904     0.3411     0.3561    \n",
            "30            12         150     50      0.2        0.1        0.9023     0.3171     0.3336    \n",
            "30            12         150     50      0.2        0.2        0.8978     0.3222     0.3407    \n",
            "30            12         100     100     0.1        0.1        0.8939     0.3111     0.3264    \n",
            "30            12         100     100     0.1        0.2        0.8852     0.3302     0.3399    \n",
            "30            12         100     100     0.2        0.1        0.8954     0.3208     0.3363    \n",
            "30            12         100     100     0.2        0.2        0.8959     0.3044     0.3269    \n",
            "30            12         100     75      0.1        0.1        0.9005     0.3226     0.3276    \n",
            "30            12         100     75      0.1        0.2        0.8960     0.3123     0.3197    \n",
            "30            12         100     75      0.2        0.1        0.8978     0.3058     0.3177    \n",
            "30            12         100     75      0.2        0.2        0.8714     0.3322     0.3557    \n",
            "30            12         100     50      0.1        0.1        0.9010     0.3167     0.3224    \n",
            "30            12         100     50      0.1        0.2        0.8973     0.3157     0.3282    \n",
            "30            12         100     50      0.2        0.1        0.8933     0.3358     0.3401    \n",
            "30            12         100     50      0.2        0.2        0.8961     0.3276     0.3430    \n",
            "30            12         75      100     0.1        0.1        0.8717     0.3262     0.3525    \n",
            "30            12         75      100     0.1        0.2        0.9010     0.3121     0.3201    \n",
            "30            12         75      100     0.2        0.1        0.8971     0.3088     0.3313    \n",
            "30            12         75      100     0.2        0.2        0.9009     0.3317     0.3571    \n",
            "30            12         75      75      0.1        0.1        0.8982     0.3241     0.3282    \n",
            "30            12         75      75      0.1        0.2        0.8962     0.3266     0.3331    \n",
            "30            12         75      75      0.2        0.1        0.8917     0.3643     0.3597    \n",
            "30            12         75      75      0.2        0.2        0.9006     0.3192     0.3289    \n",
            "30            12         75      50      0.1        0.1        0.8976     0.3497     0.3510    \n",
            "30            12         75      50      0.1        0.2        0.8956     0.3219     0.3316    \n",
            "30            12         75      50      0.2        0.1        0.8509     0.3255     0.3630    \n",
            "30            12         75      50      0.2        0.2        0.8850     0.3383     0.3633    \n"
          ]
        }
      ],
      "source": [
        "parameter_result_list1 = []\n",
        "hist_window = 30\n",
        "step_out = 12\n",
        "\n",
        "for unit1 in [150, 100, 75]:\n",
        "    for unit2 in [100, 75, 50]:\n",
        "        for drop1 in [0.1, 0.2]:\n",
        "            for drop2 in [0.1, 0.2]:\n",
        "                f1, mse, mae = modeling1(hist_window, step_out, unit1, unit2, drop1, drop2, 1)\n",
        "                parameter_result_list1.append((hist_window, step_out, unit1, unit2, drop1, drop2, f1, mse, mae))\n",
        "\n",
        "# Printing the list with comment lines indicating parameter titles\n",
        "print(\"# Hist_Window   Step_Out   Unit1   Unit2   Dropout1   Dropout2   F1    MSE       MAE\")\n",
        "for params in parameter_result_list1:\n",
        "    print(\"{:<13} {:<10} {:<7} {:<7} {:<10} {:<10} {:<10.4f} {:<10.4f} {:<10.4f}\".format(*params))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ivpbVeCFIqdJ"
      },
      "outputs": [],
      "source": [
        "# Saving the parameter_result_list to a CSV file\n",
        "with open('/content/drive/My Drive/time_series/parameter_result_list1.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerows(parameter_result_list1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JogzhJEsAzTP"
      },
      "outputs": [],
      "source": [
        "# Loading the parameter_result_list from the CSV file\n",
        "parameter_result_list = []\n",
        "\n",
        "with open('/content/drive/My Drive/time_series/parameter_result_list1.csv', 'r', newline='') as file:\n",
        "    reader = csv.reader(file)\n",
        "    for row in reader:\n",
        "        parameter_result_list.append(row)\n",
        "#parameter_result_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LLxJO_CvTu8q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36c97404-a1b0-412f-b5f5-6b270da986d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[30, 12, 150, 75, 0.1, 0.2, 0.9033698113339389, 0.3187919051768611, 0.3422593790833863]\n",
            "[30, 12, 150, 50, 0.2, 0.1, 0.9022893050609535, 0.31713817373277337, 0.3335716446234319]\n",
            "[30, 12, 75, 100, 0.1, 0.2, 0.9010283733479367, 0.3121234837013145, 0.3201110397717642]\n",
            "[30, 12, 100, 50, 0.1, 0.1, 0.9009662777746954, 0.316704360881716, 0.32244294422704856]\n",
            "[30, 12, 75, 100, 0.2, 0.2, 0.9008720538425167, 0.3317398118148993, 0.35709048551041195]\n",
            "[30, 12, 75, 75, 0.2, 0.2, 0.9005584145924985, 0.3191804988666529, 0.3289371976571081]\n",
            "[30, 12, 100, 75, 0.1, 0.1, 0.9005234902100712, 0.32259146169953173, 0.32762094304624395]\n",
            "[30, 12, 150, 100, 0.1, 0.2, 0.8996470064870349, 0.3096652224166597, 0.32584392218995745]\n",
            "[30, 12, 150, 75, 0.1, 0.1, 0.8983441288863587, 0.30799857256189955, 0.3263954781377991]\n",
            "[30, 12, 75, 75, 0.1, 0.1, 0.8982004645621711, 0.3240712695573922, 0.32824338919757284]\n",
            "[30, 12, 100, 75, 0.2, 0.1, 0.8978258680627142, 0.3058021581331728, 0.3177369318049358]\n",
            "[30, 12, 150, 50, 0.2, 0.2, 0.8977855076427985, 0.322202508299011, 0.34071973943349165]\n",
            "[30, 12, 75, 50, 0.1, 0.1, 0.8975706777223793, 0.34967349668821013, 0.35095302903513953]\n",
            "[30, 12, 100, 50, 0.1, 0.2, 0.8972868972408667, 0.3157402157942682, 0.3282403716865106]\n",
            "[30, 12, 75, 100, 0.2, 0.1, 0.8970561828388688, 0.30884661973118815, 0.3313381783535894]\n",
            "[30, 12, 150, 75, 0.2, 0.2, 0.896734492725269, 0.31319091575069025, 0.3264657771914569]\n",
            "[30, 12, 75, 75, 0.1, 0.2, 0.8962318177553285, 0.3265809060314951, 0.33314404434522543]\n",
            "[30, 12, 100, 50, 0.2, 0.2, 0.8960779071318675, 0.3276322340625595, 0.34300391983172573]\n",
            "[30, 12, 100, 75, 0.1, 0.2, 0.8960427364096295, 0.3122588004651421, 0.3196674871694842]\n",
            "[30, 12, 100, 100, 0.2, 0.2, 0.8958882346737024, 0.3043885786669295, 0.326911314911826]\n",
            "[30, 12, 75, 50, 0.1, 0.2, 0.8956160591806177, 0.3219407680688878, 0.3316226343498728]\n",
            "[30, 12, 100, 100, 0.2, 0.1, 0.8953916308879302, 0.3208252172064418, 0.3362609622198416]\n",
            "[30, 12, 150, 100, 0.2, 0.1, 0.895365311374105, 0.31963837695589536, 0.3211865663819384]\n",
            "[30, 12, 100, 100, 0.1, 0.1, 0.8938623640595684, 0.31108903014679995, 0.32643955320070106]\n",
            "[30, 12, 100, 50, 0.2, 0.1, 0.8932667771745963, 0.33583856251826266, 0.340078979303363]\n",
            "[30, 12, 150, 50, 0.1, 0.1, 0.8924883769890628, 0.34470681572846634, 0.33479001908002126]\n",
            "[30, 12, 75, 75, 0.2, 0.1, 0.8916763614508293, 0.3643254381322285, 0.35971856207908465]\n",
            "[30, 12, 150, 50, 0.1, 0.2, 0.8903573384513545, 0.3411360155644087, 0.3560671218105303]\n",
            "[30, 12, 150, 75, 0.2, 0.1, 0.8902375384211163, 0.3559557596872694, 0.35114119154492063]\n",
            "[30, 12, 150, 100, 0.2, 0.2, 0.8883835839962828, 0.3198145707745575, 0.3379809639624273]\n",
            "[30, 12, 100, 100, 0.1, 0.2, 0.8851903209354675, 0.33017510820922213, 0.33986496775165664]\n",
            "[30, 12, 75, 50, 0.2, 0.2, 0.8850115835836764, 0.33830323420745734, 0.3632818185401223]\n",
            "[30, 12, 150, 100, 0.1, 0.1, 0.8784395883154871, 0.3181722717057262, 0.3425203108974308]\n",
            "[30, 12, 75, 100, 0.1, 0.1, 0.8717022552644889, 0.3261946484875869, 0.3524700006931349]\n",
            "[30, 12, 100, 75, 0.2, 0.2, 0.8713554483023498, 0.33219226563715765, 0.3556954984919707]\n",
            "[30, 12, 75, 50, 0.2, 0.1, 0.8509442049529969, 0.3255061836263033, 0.3630221070386559]\n"
          ]
        }
      ],
      "source": [
        "# Convert all elements in the list to float\n",
        "my_list_float = [[float(val) if '.' in val else int(val) for val in sublist] for sublist in parameter_result_list]\n",
        "\n",
        "# Sort the list based on the f1 values\n",
        "sorted_list = sorted(my_list_float, key=lambda x: x[6], reverse=True)\n",
        "\n",
        "# Print the sorted list\n",
        "for sublist in sorted_list:\n",
        "    print(sublist)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}