{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/davidsherman96/mids_capstone_spring24_chang_li_sherman/blob/main/Hypertuned_State_wide_CA_drought_random_forest_multivariate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oeCE85RZaBN0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler, StandardScaler\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4dmgFLz8_ySQ"
   },
   "outputs": [],
   "source": [
    "# Set random seed for TensorFlow\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "# Set random seed for Python\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VHbe-92aulGr"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(1)\n",
    "\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XfUWkEhXh31i",
    "outputId": "403e77b4-9d2e-4658-9c0f-eaeb25bb43c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_1Ua7mbsbUOr"
   },
   "outputs": [],
   "source": [
    "data_all_county = pd.read_csv('/content/drive/MyDrive/CA_data_lat_log_weekly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nmnaIz6bfmfN"
   },
   "outputs": [],
   "source": [
    "data_all_county['date'] = pd.to_datetime(data_all_county['date'])\n",
    "data_all_county['month'] = data_all_county['date'].dt.month\n",
    "data_all_county['month'] = data_all_county['month'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkZqApXYXb-9"
   },
   "source": [
    "Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fIDCIpwSXXKt"
   },
   "outputs": [],
   "source": [
    "def ts_multi_data_prep(dataset, target, start, end, window, step_out):\n",
    "    X = []\n",
    "    y = []\n",
    "    start = start + window\n",
    "    if end is None:\n",
    "        end = len(dataset) - step_out\n",
    "        #end = len(dataset)\n",
    "    for i in range(start, end):\n",
    "        indices = range(i-window, i)\n",
    "        X.append(dataset[indices])\n",
    "\n",
    "        indicey = range(i, i+step_out) #revise the window definition\n",
    "        y.append(target[indicey])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vp6wtluEXfZb"
   },
   "outputs": [],
   "source": [
    "def timeseries_evaluation_metrics_func(y_true, y_pred):\n",
    "    def mean_absolute_percentage_error(y_true, y_pred):\n",
    "        y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "    print('Evaluation metric results:-')\n",
    "    mse = metrics.mean_squared_error(y_true.flatten(), y_pred.flatten())\n",
    "    mae = metrics.mean_absolute_error(y_true.flatten(), y_pred.flatten())\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = metrics.r2_score(y_true.flatten(), y_pred.flatten())\n",
    "    return mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DZJVpSJ_49m2"
   },
   "outputs": [],
   "source": [
    "def timeseries_evaluation_metrics_binary(y_true, y_pred):\n",
    "    print('Evaluation metric results:-')\n",
    "    accuracy = accuracy_score(y_true.flatten(), y_pred.flatten())\n",
    "    precision = precision_score(y_true.flatten(), y_pred.flatten(), average='macro')\n",
    "    recall = recall_score(y_true.flatten(), y_pred.flatten(), average='macro')\n",
    "    f1 = f1_score(y_true.flatten(), y_pred.flatten(), average='macro')\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xxvHTDdUqxyN"
   },
   "outputs": [],
   "source": [
    "def transform_county_data(x_data_array, y_data_array):\n",
    "    # Lists to store x_train_c and y_train_c arrays\n",
    "    x_c_list = []\n",
    "    y_c_list = []\n",
    "    \n",
    "    # Divide the arrays into 'unique_fips_count' number of subarrays\n",
    "    x_subarrays = np.array_split(x_data_array, unique_fips_count, axis=0)\n",
    "    y_subarrays = np.array_split(y_data_array, unique_fips_count, axis=0)\n",
    "\n",
    "    # Combine x_subarrays and y_subarrays into tuples\n",
    "    data_tuples = [(x_subarray, y_subarray) for x_subarray, y_subarray in zip(x_subarrays, y_subarrays)]\n",
    "\n",
    "    # Print or use the data tuples as needed\n",
    "    for idx, data_tuple in enumerate(data_tuples):\n",
    "        x_window_c, y_window_c = ts_multi_data_prep(data_tuple[0],data_tuple[1], 0, None, hist_window, step_out)\n",
    "        # Append x_window_c and y_window_c arrays to lists\n",
    "        x_c_list.append(x_window_c)\n",
    "        y_c_list.append(y_window_c)\n",
    "\n",
    "    # Stack arrays in lists to create x_train_c and y_train_c\n",
    "    x_all_county = np.vstack(x_c_list)\n",
    "    y_all_county = np.vstack(y_c_list)\n",
    "\n",
    "    return x_all_county, y_all_county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BJyFdGZFeeVi"
   },
   "outputs": [],
   "source": [
    "x_train_c, y_train_c, x_vali_c, y_vali_c, x_test_c, y_test_c = [], [], [], [], [], []\n",
    "unique_fips = data_all_county['fips'].unique()\n",
    "unique_fips_count = data_all_county['fips'].nunique()\n",
    "\n",
    "for fips in unique_fips:\n",
    "    # Extract dataframe for the current FIPS value\n",
    "    data_county = data_all_county[data_all_county['fips'] == fips]\n",
    "\n",
    "    X_data = data_county[['lat','lon','PRECTOT', 'PS', 'QV2M', 'T2M', 'T2MDEW', 'T2MWET',\n",
    "       'T2M_MAX', 'T2M_MIN', 'T2M_RANGE', 'TS', 'WS10M', 'WS10M_MAX',\n",
    "       'WS10M_MIN', 'WS10M_RANGE', 'WS50M', 'WS50M_MAX', 'WS50M_MIN',\n",
    "       'WS50M_RANGE', 'score', 'month']]\n",
    "   \n",
    "    Y_data = data_county[['score']]\n",
    "    #train_val_test split 70%-10%-20%\n",
    "    n = len(X_data)\n",
    "\n",
    "    x_train_county = X_data[0:int(n*0.7)]\n",
    "    y_train_county = Y_data[0:int(n*0.7)]\n",
    "    x_vali_county = X_data[int(n*0.7):int(n*0.8)]\n",
    "    y_vali_county = Y_data[int(n*0.7):int(n*0.8)]\n",
    "    x_test_county = X_data[int(n*0.8):]\n",
    "    y_test_county = Y_data[int(n*0.8):]\n",
    "\n",
    "\n",
    "    if fips == 6001:\n",
    "        x_train_c, y_train_c, x_vali_c, y_vali_c, x_test_c, y_test_c = x_train_county, y_train_county, x_vali_county, y_vali_county, x_test_county, y_test_county\n",
    "\n",
    "    else:\n",
    "        x_train_c = np.concatenate((x_train_c, x_train_county), axis=0)\n",
    "        y_train_c = np.concatenate((y_train_c, y_train_county), axis=0)\n",
    "        x_vali_c = np.concatenate((x_vali_c, x_vali_county), axis=0)\n",
    "        y_vali_c = np.concatenate((y_vali_c, y_vali_county), axis=0)\n",
    "        x_test_c = np.concatenate((x_test_c, x_test_county), axis=0)\n",
    "        y_test_c = np.concatenate((y_test_c, y_test_county), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "MjYfAZXoYPE7"
   },
   "outputs": [],
   "source": [
    "X_scaler_train = MinMaxScaler()\n",
    "Y_scaler_train = MinMaxScaler()\n",
    "X_scaler_test = MinMaxScaler()\n",
    "Y_scaler_test = MinMaxScaler()\n",
    "X_scaler_vali = MinMaxScaler()\n",
    "Y_scaler_vali = MinMaxScaler()\n",
    "x_train_data = X_scaler_train.fit_transform(x_train_c)\n",
    "y_train_data = Y_scaler_train.fit_transform(y_train_c)\n",
    "x_vali_data = X_scaler_vali.fit_transform(x_vali_c)\n",
    "y_vali_data = Y_scaler_vali.fit_transform(y_vali_c)\n",
    "x_test_data = X_scaler_test.fit_transform(x_test_c)\n",
    "y_test_data = Y_scaler_test.fit_transform(y_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "NOygAYEWhEHl"
   },
   "outputs": [],
   "source": [
    "def modeling1(hist_window,\n",
    "              step_out,\n",
    "              num_estimators,\n",
    "              max_depth,\n",
    "              random_state,\n",
    "              flag_report):\n",
    "\n",
    "  x_train, y_train = transform_county_data(x_train_data, y_train_data)\n",
    "  x_vali, y_vali = transform_county_data(x_vali_data, y_vali_data)\n",
    "  x_test, y_test = transform_county_data(x_test_data, y_test_data)\n",
    "\n",
    "  # Convert all the 3D arrays to 2D for Random Forest\n",
    "  train_len = len(x_train)\n",
    "  num_features = X_data.shape[1]\n",
    "  vali_len = len(x_vali)\n",
    "  test_len = len(x_test)\n",
    "\n",
    "  # Reshape the labels into a simple 2D array\n",
    "  y_train = y_train.reshape(train_len, step_out)\n",
    "  y_vali = y_vali.reshape(vali_len, step_out)\n",
    "  y_test = y_test.reshape(test_len, step_out)\n",
    "\n",
    "  # Reshape the x data into a 2D array of (num windows, window size x features size)\n",
    "  x_train = x_train.reshape(train_len, hist_window * num_features)\n",
    "  x_vali = x_vali.reshape(vali_len, hist_window * num_features)\n",
    "  x_test = x_test.reshape(test_len, hist_window * num_features)\n",
    "\n",
    "  # fit the model\n",
    "  model = RandomForestRegressor(n_estimators=num_estimators,\n",
    "                                max_depth = max_depth,\n",
    "                                random_state = random_state)\n",
    "  model.fit(x_train, y_train)\n",
    "\n",
    "  # Get predictions\n",
    "  y_test_pred = model.predict(x_test)\n",
    "\n",
    "  # Convert predictions back onto real scale\n",
    "  y_test_pred_Inverse = Y_scaler_test.inverse_transform(y_test_pred)\n",
    "  y_test_pred_Inverse_ordinal = np.round(y_test_pred_Inverse).astype(int)\n",
    "  y_test_Inverse = Y_scaler_test.inverse_transform(y_test)\n",
    "  y_test_Inverse_ordinal = np.round(y_test_Inverse).astype(int)\n",
    "\n",
    "  # Get evaluation mtrics\n",
    "  mse, mae = timeseries_evaluation_metrics_func(y_test_Inverse,y_test_pred_Inverse)\n",
    "\n",
    "  # Get the binary classification evaluation metrics\n",
    "  threshold = 2.5\n",
    "  y_test_Inverse_binary = np.where(y_test_Inverse >= threshold, 1, 0)\n",
    "  y_test_pred_Inverse_binary = np.where(y_test_pred_Inverse >= threshold, 1, 0)\n",
    "  f1 = timeseries_evaluation_metrics_binary(y_test_Inverse_binary,y_test_pred_Inverse_binary)\n",
    "\n",
    "  # Print the classification report\n",
    "  if flag_report:\n",
    "    classification_metrics = classification_report(y_test_Inverse_binary.flatten(),y_test_pred_Inverse_binary.flatten())\n",
    "    print(classification_metrics)\n",
    "\n",
    "  print(f'Number of estimators: {num_estimators}, Max depth: {max_depth}, Random state: {random_state}, F1: {f1}, MSE: {mse}, MAE: {mae}')\n",
    "\n",
    "  return f1, mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fWn72P8efmfR",
    "outputId": "b551a6d1-1242-4e6f-b430-b0a48eba45ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metric results:-\n",
      "Evaluation metric results:-\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93    110778\n",
      "           1       0.42      0.53      0.47     13110\n",
      "\n",
      "    accuracy                           0.87    123888\n",
      "   macro avg       0.68      0.72      0.70    123888\n",
      "weighted avg       0.89      0.87      0.88    123888\n",
      "\n",
      "Number of estimators: 100, Max depth: 1, Random state: 123, F1: 0.69737861711576, MSE: 0.5000430613975385, MAE: 0.5570079307478641\n",
      "Evaluation metric results:-\n",
      "Evaluation metric results:-\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93    110778\n",
      "           1       0.42      0.53      0.47     13110\n",
      "\n",
      "    accuracy                           0.87    123888\n",
      "   macro avg       0.68      0.72      0.70    123888\n",
      "weighted avg       0.89      0.87      0.88    123888\n",
      "\n",
      "Number of estimators: 100, Max depth: 1, Random state: 0, F1: 0.6967895133968602, MSE: 0.5013309557734139, MAE: 0.5574087713504433\n",
      "Evaluation metric results:-\n",
      "Evaluation metric results:-\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93    110778\n",
      "           1       0.42      0.53      0.47     13110\n",
      "\n",
      "    accuracy                           0.87    123888\n",
      "   macro avg       0.68      0.72      0.70    123888\n",
      "weighted avg       0.89      0.87      0.88    123888\n",
      "\n",
      "Number of estimators: 100, Max depth: 1, Random state: 42, F1: 0.6979901398661895, MSE: 0.5009611808618245, MAE: 0.5573822320798181\n",
      "Evaluation metric results:-\n",
      "Evaluation metric results:-\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97    110778\n",
      "           1       0.93      0.53      0.67     13110\n",
      "\n",
      "    accuracy                           0.95    123888\n",
      "   macro avg       0.94      0.76      0.82    123888\n",
      "weighted avg       0.95      0.95      0.94    123888\n",
      "\n",
      "Number of estimators: 100, Max depth: 2, Random state: 123, F1: 0.8216815960139914, MSE: 0.35097786998834224, MAE: 0.39086939248287017\n",
      "Evaluation metric results:-\n",
      "Evaluation metric results:-\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97    110778\n",
      "           1       0.93      0.54      0.68     13110\n",
      "\n",
      "    accuracy                           0.95    123888\n",
      "   macro avg       0.94      0.77      0.83    123888\n",
      "weighted avg       0.95      0.95      0.94    123888\n",
      "\n",
      "Number of estimators: 100, Max depth: 2, Random state: 0, F1: 0.8266774355448667, MSE: 0.35095299855523365, MAE: 0.3905100660130562\n",
      "Evaluation metric results:-\n",
      "Evaluation metric results:-\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97    110778\n",
      "           1       0.93      0.54      0.68     13110\n",
      "\n",
      "    accuracy                           0.95    123888\n",
      "   macro avg       0.94      0.77      0.83    123888\n",
      "weighted avg       0.95      0.95      0.94    123888\n",
      "\n",
      "Number of estimators: 100, Max depth: 2, Random state: 42, F1: 0.8265636454616385, MSE: 0.35016811900199174, MAE: 0.3897036304786059\n",
      "Evaluation metric results:-\n",
      "Evaluation metric results:-\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97    110778\n",
      "           1       0.94      0.52      0.67     13110\n",
      "\n",
      "    accuracy                           0.95    123888\n",
      "   macro avg       0.94      0.76      0.82    123888\n",
      "weighted avg       0.95      0.95      0.94    123888\n",
      "\n",
      "Number of estimators: 100, Max depth: 3, Random state: 123, F1: 0.8207513058812219, MSE: 0.33436819596557843, MAE: 0.38944364671414955\n",
      "Evaluation metric results:-\n",
      "Evaluation metric results:-\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97    110778\n",
      "           1       0.94      0.53      0.68     13110\n",
      "\n",
      "    accuracy                           0.95    123888\n",
      "   macro avg       0.94      0.76      0.82    123888\n",
      "weighted avg       0.95      0.95      0.94    123888\n",
      "\n",
      "Number of estimators: 100, Max depth: 3, Random state: 0, F1: 0.8238038183239547, MSE: 0.3334061969633288, MAE: 0.3881192998174195\n",
      "Evaluation metric results:-\n",
      "Evaluation metric results:-\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97    110778\n",
      "           1       0.94      0.53      0.68     13110\n",
      "\n",
      "    accuracy                           0.95    123888\n",
      "   macro avg       0.94      0.76      0.82    123888\n",
      "weighted avg       0.95      0.95      0.94    123888\n",
      "\n",
      "Number of estimators: 100, Max depth: 3, Random state: 42, F1: 0.8236663202363537, MSE: 0.33364480854979706, MAE: 0.38848487308692514\n",
      "# Hist_Window   Step_Out   Num Estimators  Max Depth   Random State    F1    MSE       MAE\n",
      "30            12         100     1       123        0.6974     0.5000     0.5570    \n",
      "30            12         100     1       0          0.6968     0.5013     0.5574    \n",
      "30            12         100     1       42         0.6980     0.5010     0.5574    \n",
      "30            12         100     2       123        0.8217     0.3510     0.3909    \n",
      "30            12         100     2       0          0.8267     0.3510     0.3905    \n",
      "30            12         100     2       42         0.8266     0.3502     0.3897    \n",
      "30            12         100     3       123        0.8208     0.3344     0.3894    \n",
      "30            12         100     3       0          0.8238     0.3334     0.3881    \n",
      "30            12         100     3       42         0.8237     0.3336     0.3885    \n"
     ]
    }
   ],
   "source": [
    "parameter_result_list1 = []\n",
    "hist_window = 30\n",
    "step_out = 12\n",
    "\n",
    "for num_estimators in [100]:\n",
    "    for max_depth in [1,2,3]:\n",
    "        for random_state in [123, 0, 42]:\n",
    "              f1, mse, mae = modeling1(hist_window,\n",
    "                             step_out,\n",
    "                             num_estimators,\n",
    "                             max_depth,\n",
    "                             random_state,\n",
    "                             flag_report = 1)\n",
    "              parameter_result_list1.append((hist_window,\n",
    "                                   step_out,\n",
    "                                   num_estimators,\n",
    "                                   max_depth,\n",
    "                                   random_state,\n",
    "                                   f1, mse, mae))\n",
    "\n",
    "# Printing the list with comment lines indicating parameter titles\n",
    "print(\"# Hist_Window   Step_Out   Num Estimators  Max Depth   Random State    F1    MSE       MAE\")\n",
    "for params in parameter_result_list1:\n",
    "    print(\"{:<13} {:<10} {:<7} {:<7} {:<10} {:<10.4f} {:<10.4f} {:<10.4f}\".format(*params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ivpbVeCFIqdJ"
   },
   "outputs": [],
   "source": [
    "# Saving the parameter_result_list to a CSV file\n",
    "with open('/content/drive/MyDrive/random_forest_parameter_result_list1.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(parameter_result_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "JogzhJEsAzTP"
   },
   "outputs": [],
   "source": [
    "# Loading the parameter_result_list from the CSV file\n",
    "parameter_result_list = []\n",
    "\n",
    "with open('/content/drive/MyDrive/random_forest_parameter_result_list1.csv', 'r', newline='') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        parameter_result_list.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LLxJO_CvTu8q",
    "outputId": "6d0a9a87-dc54-4b2e-bbe7-46ce71775ae4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 12, 100, 1, 0, 0.6967895133968602, 0.5013309557734139, 0.5574087713504433]\n",
      "[30, 12, 100, 1, 42, 0.6979901398661895, 0.5009611808618245, 0.5573822320798181]\n",
      "[30, 12, 100, 1, 123, 0.69737861711576, 0.5000430613975385, 0.5570079307478641]\n",
      "[30, 12, 100, 2, 123, 0.8216815960139914, 0.35097786998834224, 0.39086939248287017]\n",
      "[30, 12, 100, 2, 0, 0.8266774355448667, 0.35095299855523365, 0.3905100660130562]\n",
      "[30, 12, 100, 2, 42, 0.8265636454616385, 0.35016811900199174, 0.3897036304786059]\n",
      "[30, 12, 100, 3, 123, 0.8207513058812219, 0.33436819596557843, 0.38944364671414955]\n",
      "[30, 12, 100, 3, 42, 0.8236663202363537, 0.33364480854979706, 0.38848487308692514]\n",
      "[30, 12, 100, 3, 0, 0.8238038183239547, 0.3334061969633288, 0.3881192998174195]\n"
     ]
    }
   ],
   "source": [
    "# Convert all elements in the list to float\n",
    "my_list_float = [[float(val) if '.' in val else int(val) for val in sublist] for sublist in parameter_result_list]\n",
    "\n",
    "# Sort the list based on the f1 values\n",
    "sorted_list = sorted(my_list_float, key=lambda x: x[6], reverse=True)\n",
    "\n",
    "# Print the sorted list\n",
    "for sublist in sorted_list:\n",
    "    print(sublist)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
