{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeCE85RZaBN0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder,MinMaxScaler, StandardScaler\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for TensorFlow\n",
        "tf.random.set_seed(123)\n",
        "\n",
        "# Set random seed for Python\n",
        "np.random.seed(123)"
      ],
      "metadata": {
        "id": "VM9KaUKABGsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfUWkEhXh31i",
        "outputId": "602fd1dd-cde6-48f6-8e10-2f9f5f2e6615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1Ua7mbsbUOr"
      },
      "source": [
        "\n",
        "data_all_county = pd.read_csv('/content/drive/My Drive/time_series/CA_data_lat_log_weekly.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define helper functions"
      ],
      "metadata": {
        "id": "JkZqApXYXb-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ts_multi_data_prep(dataset, target, start, end, window, step_out):\n",
        "    X = []\n",
        "    y = []\n",
        "    start = start + window\n",
        "    if end is None:\n",
        "        end = len(dataset) - step_out\n",
        "        #end = len(dataset)\n",
        "    for i in range(start, end):\n",
        "        indices = range(i-window, i)\n",
        "        X.append(dataset[indices])\n",
        "\n",
        "        indicey = range(i, i+step_out) #revise the window definition\n",
        "        y.append(target[indicey])\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "fIDCIpwSXXKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def timeseries_evaluation_metrics_func(y_true, y_pred):\n",
        "    def mean_absolute_percentage_error(y_true, y_pred):\n",
        "        y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "    print('Evaluation metric results:-')\n",
        "    mse = metrics.mean_squared_error(y_true.flatten(), y_pred.flatten())\n",
        "    mae = metrics.mean_absolute_error(y_true.flatten(), y_pred.flatten())\n",
        "    rmse = np.sqrt(mse)\n",
        "    #mape = mean_absolute_percentage_error(y_true.flatten(), y_pred.flatten())\n",
        "    r2 = metrics.r2_score(y_true.flatten(), y_pred.flatten())\n",
        "    print(f'MSE is : {mse}')\n",
        "    print(f'MAE is : {mae}')\n",
        "    print(f'RMSE is : {rmse}')\n",
        "    #print(f'MAPE is : {mape}')\n",
        "    print(f'R2 is : {r2}\\n')"
      ],
      "metadata": {
        "id": "vp6wtluEXfZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def timeseries_evaluation_metrics_binary(y_true, y_pred):\n",
        "    print('Evaluation metric results:-')\n",
        "    accuracy = accuracy_score(y_true.flatten(), y_pred.flatten())\n",
        "    precision = precision_score(y_true.flatten(), y_pred.flatten(), average='macro')\n",
        "    recall = recall_score(y_true.flatten(), y_pred.flatten(), average='macro')\n",
        "    f1 = f1_score(y_true.flatten(), y_pred.flatten(), average='macro')\n",
        "\n",
        "    print(f'Accuracy: {accuracy}')\n",
        "    print(f'Precision: {precision}')\n",
        "    print(f'Recall: {recall}')\n",
        "    print(f'F1-score: {f1}\\n')"
      ],
      "metadata": {
        "id": "832FGB3O-M1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def single_evaluation_metrics_func(y_true, y_pred):\n",
        "    def mean_absolute_percentage_error(y_true, y_pred):\n",
        "        y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "    print('Evaluation metric results:-')\n",
        "    print(f'MSE is : {metrics.mean_squared_error(y_true, y_pred)}')\n",
        "    print(f'MAE is : {metrics.mean_absolute_error(y_true, y_pred)}')\n",
        "    print(f'RMSE is : {np.sqrt(metrics.mean_squared_error(y_true, y_pred))}')\n",
        "    #print(f'MAPE is : {mean_absolute_percentage_error(y_true, y_pred)}')\n",
        "    print(f'R2 is : {metrics.r2_score(y_true, y_pred)}',end='\\n\\n')"
      ],
      "metadata": {
        "id": "pUCiqC7cXfMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_county_level_func(data_county, step_out):\n",
        "\n",
        "    X_scaler_train = MinMaxScaler()\n",
        "    Y_scaler_train = MinMaxScaler()\n",
        "    X_scaler_test = MinMaxScaler()\n",
        "    Y_scaler_test = MinMaxScaler()\n",
        "    X_scaler_vali = MinMaxScaler()\n",
        "    Y_scaler_vali = MinMaxScaler()\n",
        "\n",
        "\n",
        "    X_data = data_county[['score']]\n",
        "    Y_data = data_county[['score']]\n",
        "\n",
        "\n",
        "    #train_val_test split 70%-10%-20%\n",
        "    n = len(X_data)\n",
        "    x_train_data = X_scaler_train.fit_transform(X_data[0:int(n*0.7)])\n",
        "    y_train_data = Y_scaler_train.fit_transform(Y_data[0:int(n*0.7)])\n",
        "    x_vali_data = X_scaler_vali.fit_transform(X_data[int(n*0.7):int(n*0.8)])\n",
        "    y_vali_data = Y_scaler_vali.fit_transform(Y_data[int(n*0.7):int(n*0.8)])\n",
        "    x_test_data = X_scaler_test.fit_transform(X_data[int(n*0.8):])\n",
        "    y_test_data = Y_scaler_test.fit_transform(Y_data[int(n*0.8):])\n",
        "    x_train_c, y_train_c = ts_multi_data_prep(x_train_data, y_train_data, 0, None, hist_window, step_out)\n",
        "    x_vali_c, y_vali_c = ts_multi_data_prep(x_vali_data, y_vali_data, 0, None, hist_window, step_out)\n",
        "    x_test_c, y_test_c = ts_multi_data_prep(x_test_data, y_test_data, 0, None, hist_window, step_out)\n",
        "    return x_train_c, y_train_c, x_vali_c, y_vali_c, x_test_c, y_test_c"
      ],
      "metadata": {
        "id": "tnEg3zV9XfCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJyFdGZFeeVi"
      },
      "source": [
        "hist_window = 30\n",
        "step_out = 12\n",
        "x_train_c, y_train_c, x_vali_c, y_vali_c, x_test_c, y_test_c = [], [], [], [], [], []\n",
        "unique_fips = data_all_county['fips'].unique()\n",
        "unique_fips_count = data_all_county['fips'].nunique()\n",
        "for fips in unique_fips:\n",
        "    # Extract dataframe for the current FIPS value\n",
        "    data_county = data_all_county[data_all_county['fips'] == fips]\n",
        "\n",
        "    X_data = data_county[['score']]\n",
        "    Y_data = data_county[['score']]\n",
        "    #train_val_test split 70%-10%-20%\n",
        "    n = len(X_data)\n",
        "\n",
        "    x_train_county = X_data[0:int(n*0.7)]\n",
        "    y_train_county = Y_data[0:int(n*0.7)]\n",
        "    x_vali_county = X_data[int(n*0.7):int(n*0.8)]\n",
        "    y_vali_county = Y_data[int(n*0.7):int(n*0.8)]\n",
        "    x_test_county = X_data[int(n*0.8):]\n",
        "    y_test_county = Y_data[int(n*0.8):]\n",
        "\n",
        "\n",
        "    if fips == 6001:\n",
        "        x_train_c, y_train_c, x_vali_c, y_vali_c, x_test_c, y_test_c = x_train_county, y_train_county, x_vali_county, y_vali_county, x_test_county, y_test_county\n",
        "\n",
        "    else:\n",
        "        x_train_c = np.concatenate((x_train_c, x_train_county), axis=0)\n",
        "        y_train_c = np.concatenate((y_train_c, y_train_county), axis=0)\n",
        "        x_vali_c = np.concatenate((x_vali_c, x_vali_county), axis=0)\n",
        "        y_vali_c = np.concatenate((y_vali_c, y_vali_county), axis=0)\n",
        "        x_test_c = np.concatenate((x_test_c, x_test_county), axis=0)\n",
        "        y_test_c = np.concatenate((y_test_c, y_test_county), axis=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_c.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3FihSH-Z4jM",
        "outputId": "1706ca12-0d4b-4851-f02c-4b5c43767e0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44486, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_vali_c.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHsEsXrqaxrU",
        "outputId": "a432e159-66df-415a-a11b-5e9826414a33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6322, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_scaler_train = MinMaxScaler()\n",
        "Y_scaler_train = MinMaxScaler()\n",
        "X_scaler_test = MinMaxScaler()\n",
        "Y_scaler_test = MinMaxScaler()\n",
        "X_scaler_vali = MinMaxScaler()\n",
        "Y_scaler_vali = MinMaxScaler()\n",
        "x_train_data = X_scaler_train.fit_transform(x_train_c)\n",
        "y_train_data = Y_scaler_train.fit_transform(y_train_c)\n",
        "x_vali_data = X_scaler_vali.fit_transform(x_vali_c)\n",
        "y_vali_data = Y_scaler_vali.fit_transform(y_vali_c)\n",
        "x_test_data = X_scaler_test.fit_transform(x_test_c)\n",
        "y_test_data = Y_scaler_test.fit_transform(y_test_c)"
      ],
      "metadata": {
        "id": "MjYfAZXoYPE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3k9VE_AYtbb",
        "outputId": "7340b26d-bdde-461e-c08a-023ff1fb13c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44486, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_county_data(x_data_array, y_data_array):\n",
        "    # Lists to store x_train_c and y_train_c arrays\n",
        "    x_c_list = []\n",
        "    y_c_list = []\n",
        "    # Divide the arrays into 'unique_fips_count' number of subarrays\n",
        "    x_subarrays = np.array_split(x_data_array, unique_fips_count, axis=0)\n",
        "    y_subarrays = np.array_split(y_data_array, unique_fips_count, axis=0)\n",
        "\n",
        "    # Combine x_subarrays and y_subarrays into tuples\n",
        "    data_tuples = [(x_subarray, y_subarray) for x_subarray, y_subarray in zip(x_subarrays, y_subarrays)]\n",
        "\n",
        "    # Print or use the data tuples as needed\n",
        "    for idx, data_tuple in enumerate(data_tuples):\n",
        "        x_window_c, y_window_c = ts_multi_data_prep(data_tuple[0],data_tuple[1], 0, None, hist_window, step_out)\n",
        "        # Append x_window_c and y_window_c arrays to lists\n",
        "        x_c_list.append(x_window_c)\n",
        "        y_c_list.append(y_window_c)\n",
        "\n",
        "    # Stack arrays in lists to create x_train_c and y_train_c\n",
        "    x_all_county = np.vstack(x_c_list)\n",
        "    y_all_county = np.vstack(y_c_list)\n",
        "\n",
        "    return x_all_county, y_all_county"
      ],
      "metadata": {
        "id": "swPddKW7dyDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = transform_county_data(x_train_data, y_train_data)\n",
        "x_vali, y_vali = transform_county_data(x_vali_data, y_vali_data)\n",
        "x_test, y_test = transform_county_data(x_test_data, y_test_data)"
      ],
      "metadata": {
        "id": "NOygAYEWhEHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TboDAisnwNr4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc0f1d41-8a09-4c53-acfb-92e137e52f7a"
      },
      "source": [
        "print ('Multiple window of past history\\n')\n",
        "print(x_train[0])\n",
        "print ('\\n Target\\n')\n",
        "print (y_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiple window of past history\n",
            "\n",
            "[[0.12158]\n",
            " [0.10072]\n",
            " [0.     ]\n",
            " [0.     ]\n",
            " [0.     ]\n",
            " [0.     ]\n",
            " [0.     ]\n",
            " [0.     ]\n",
            " [0.     ]\n",
            " [0.     ]\n",
            " [0.     ]\n",
            " [0.     ]\n",
            " [0.     ]\n",
            " [0.     ]\n",
            " [0.     ]\n",
            " [0.     ]\n",
            " [0.     ]\n",
            " [0.     ]\n",
            " [0.     ]\n",
            " [0.     ]\n",
            " [0.     ]\n",
            " [0.     ]\n",
            " [0.     ]\n",
            " [0.     ]\n",
            " [0.     ]\n",
            " [0.     ]\n",
            " [0.     ]\n",
            " [0.     ]\n",
            " [0.     ]\n",
            " [0.     ]]\n",
            "\n",
            " Target\n",
            "\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5XscHpjLC9n"
      },
      "source": [
        "batch_size = 32\n",
        "buffer_size = 256\n",
        "\n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_data = train_data.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
        "\n",
        "val_data = tf.data.Dataset.from_tensor_slices((x_vali, y_vali))\n",
        "val_data = val_data.batch(batch_size).repeat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i-cWA8JVdbQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo4cY_RoLc5V"
      },
      "source": [
        "class MultiStepLastBaseline(tf.keras.Model):\n",
        "  #def call(self, inputs):\n",
        "    #return tf.tile(inputs[:, -1:, :], [1, step_out, 1])\n",
        "    #return inputs[:, -n_step:, :]\n",
        "    def __init__(self, step_out):\n",
        "        super(MultiStepLastBaseline, self).__init__()\n",
        "        self.step_out = step_out\n",
        "\n",
        "    def call(self, inputs):\n",
        "        last_step_mean = tf.reduce_mean(inputs[:, -self.step_out:, :], axis=1, keepdims=True)\n",
        "        return tf.tile(last_step_mean, [1, self.step_out, 1])\n",
        "\n",
        "persistence_baseline = MultiStepLastBaseline(step_out)\n",
        "persistence_baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "                      metrics=[tf.keras.metrics.MeanAbsoluteError()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ5UemXB9GFq",
        "outputId": "225c887d-27b5-497d-9b52-ba2254f3ec39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10324, 30, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = persistence_baseline.predict(x_test)\n",
        "predicted_reshaped = np.squeeze(y_test_pred, axis=2)  # Remove the single batch dimension\n",
        "y_test_pred_Inverse = Y_scaler_test.inverse_transform(predicted_reshaped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dieOS1gtACZl",
        "outputId": "52224880-f58d-47bf-8c7a-9113274a4e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "323/323 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred_Inverse_ordinal = np.round(y_test_pred_Inverse).astype(int)"
      ],
      "metadata": {
        "id": "PXnu6p6yBunb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_reshaped = np.squeeze(y_test, axis=-1)"
      ],
      "metadata": {
        "id": "9YOMP6wqDtx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_Inverse = Y_scaler_test.inverse_transform(y_test_reshaped)\n",
        "y_test_Inverse_ordinal = np.round(y_test_Inverse).astype(int)"
      ],
      "metadata": {
        "id": "bnW2ulBKBaPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 2.5\n",
        "y_test_Inverse_binary = np.where(y_test_Inverse >= threshold, 1, 0)\n",
        "y_test_pred_Inverse_binary = np.where(y_test_pred_Inverse >= threshold, 1, 0)"
      ],
      "metadata": {
        "id": "ft8X4R3W-YdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timeseries_evaluation_metrics_func(y_test_Inverse,y_test_pred_Inverse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG4-pVPVAgLy",
        "outputId": "23faa8e3-1359-4723-93eb-529d2a039745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation metric results:-\n",
            "MSE is : 0.4997515431507381\n",
            "MAE is : 0.4344043537573488\n",
            "RMSE is : 0.7069310738330422\n",
            "R2 is : 0.5368332606976898\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "timeseries_evaluation_metrics_func(y_test_Inverse_ordinal,y_test_pred_Inverse_ordinal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aWAH6oE7N1t",
        "outputId": "1f1689e9-9149-4561-94ef-0c649825c020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation metric results:-\n",
            "MSE is : 0.632288841534289\n",
            "MAE is : 0.4456040940204055\n",
            "RMSE is : 0.7951659207576045\n",
            "R2 is : 0.44989716049744677\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7s-ib2GWuJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a14ef91-6cc2-450b-dd0d-8b4513ef4a16"
      },
      "source": [
        "timeseries_evaluation_metrics_binary(y_test_Inverse_binary,y_test_pred_Inverse_binary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation metric results:-\n",
            "Accuracy: 0.9413018209996126\n",
            "Precision: 0.9019797306627104\n",
            "Recall: 0.7620969318189846\n",
            "F1-score: 0.8131934194341599\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute classification report\n",
        "classification_metrics = classification_report(y_test_Inverse_binary.flatten(),y_test_pred_Inverse_binary.flatten())\n",
        "#classification_metrics = classification_report(y_test_Inverse_ordinal.flatten(),y_test_pred_Inverse_ordinal.flatten())\n",
        "# Print classification report\n",
        "print(classification_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtdH3aXK-wle",
        "outputId": "db9b2aa9-4e56-418f-ea8c-0b12b16f3871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97    110778\n",
            "           1       0.86      0.53      0.66     13110\n",
            "\n",
            "    accuracy                           0.94    123888\n",
            "   macro avg       0.90      0.76      0.81    123888\n",
            "weighted avg       0.94      0.94      0.94    123888\n",
            "\n"
          ]
        }
      ]
    }
  ]
}